{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Here I will try to implement ResNet 50 on the 102 Flowers dataset. I begin with loading the data. Then  I train and evaluate the performance of ResNet 50 on the loaded data.**","metadata":{}},{"cell_type":"code","source":"# Downloading the main data files\n!wget http://www.robots.ox.ac.uk/~vgg/data/flowers/102/102flowers.tgz\n!tar -xzf 102flowers.tgz\n!rm 102flowers.tgz\n!wget http://www.robots.ox.ac.uk/~vgg/data/flowers/102/imagelabels.mat","metadata":{"execution":{"iopub.status.busy":"2023-10-04T18:44:28.540782Z","iopub.execute_input":"2023-10-04T18:44:28.541630Z","iopub.status.idle":"2023-10-04T18:44:56.000080Z","shell.execute_reply.started":"2023-10-04T18:44:28.541567Z","shell.execute_reply":"2023-10-04T18:44:55.998628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Importing Needed Libraries\nimport tarfile as tf\nimport os\nimport numpy as np\nimport torch\nfrom torchvision import datasets, models, transforms\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nfrom scipy.io import loadmat\nfrom tqdm import tqdm\nfrom matplotlib import pyplot as plt\nfrom sklearn.model_selection import train_test_split as tts\nfrom keras.utils import to_categorical\nfrom collections import Counter\n\nprint ('Import Completed')\n\ndef set_device(): # Function to help with determining the accelerator\n  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n  if device == 'cuda':\n    print('GPU yay!')\n  elif device == 'cpu':\n    print('CPU :|')\n  return device\nDEVICE = set_device()","metadata":{"execution":{"iopub.status.busy":"2023-10-04T18:44:56.003483Z","iopub.execute_input":"2023-10-04T18:44:56.004627Z","iopub.status.idle":"2023-10-04T18:45:07.210456Z","shell.execute_reply.started":"2023-10-04T18:44:56.004574Z","shell.execute_reply":"2023-10-04T18:45:07.209490Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the images from the folder into a python list, as numpy arrays\nimage_folder = \"/kaggle/working/jpg\"\nall_imgs = list()\nall_labels = []\nfor img_name in tqdm(os.listdir(image_folder)):\n    image_path = os.path.join(image_folder, img_name)\n    img = Image.open(image_path)\n    img_array = np.array(img)\n    all_imgs.append(img_array)\n    all_labels.append(int(img_name[6:11])-1)\n    # see whether there are any images with different shapes or dimensions in the dataset\n    if len(img_array.shape) != 3 or img_array.shape[2] != 3:\n        print('Differing dimension/shape detected!')\n\nprint(f\"Number of total images is: {len(all_imgs)}\")","metadata":{"execution":{"iopub.status.busy":"2023-10-04T18:45:07.211733Z","iopub.execute_input":"2023-10-04T18:45:07.212935Z","iopub.status.idle":"2023-10-04T18:45:32.113770Z","shell.execute_reply.started":"2023-10-04T18:45:07.212899Z","shell.execute_reply":"2023-10-04T18:45:32.112782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the Labels as Mat objects and explore them\nimg_labels = loadmat(\"imagelabels.mat\")\nprint(img_labels.keys())\nimg_labels = img_labels['labels'][0]\nprint(f\"Number of total labels is: {len(img_labels)}\")\n\n# convert the indices in all_labels list to the actual label of their corresponding image\nall_labels = [img_labels[i] - 1 for i in all_labels] # Since the to_categorical function expects values to start from 0,\nprint(f\"Range of labels: {min(all_labels)} - {max(all_labels)}\") # I subtract 1 from all label values.\n\n# convert numbers to\nall_labels = to_categorical(all_labels, num_classes = 102, dtype = float)\n\nprint(f\"Number of classes: {all_labels.shape[1]}\")\n\n# To make sure there are enough examples for each of the labels, Let's check the min and max occurences.\nlabel_counts = Counter(img_labels)\nprint(f\"Most repeated label is {label_counts.most_common()[0][0]}: {label_counts.most_common()[0][1]} times\")\nprint(f\"Least repeated label is {label_counts.most_common()[-1][0]}: {label_counts.most_common()[-1][1]} times\")","metadata":{"execution":{"iopub.status.busy":"2023-10-04T18:45:32.115907Z","iopub.execute_input":"2023-10-04T18:45:32.116725Z","iopub.status.idle":"2023-10-04T18:45:32.152085Z","shell.execute_reply.started":"2023-10-04T18:45:32.116691Z","shell.execute_reply":"2023-10-04T18:45:32.151087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# And now let's visualize the distribution of frequencies:\nvalues = label_counts.keys()\ncounts = label_counts.values()\nplt.bar(values, counts)\n# Generate a uniform distribution to visually compare with our data\nnum_samples = len(img_labels)\nmin_value = min(img_labels)\nmax_value = max(img_labels)\nuniform_data = np.random.randint(min_value, max_value + 1, num_samples) # create a uniform distribution within the same range\n\n# Count the occurrences of each value in the uniform distribution\nuniform_value_counts = Counter(uniform_data)\n\n# Extract values and counts for plotting\nuniform_values = list(uniform_value_counts.keys())\nuniform_counts = list(uniform_value_counts.values())\n# Create the bar chart\nplt.bar(uniform_values, uniform_counts, alpha=0.25, color='red', label='Uniform Distribution')\n\nplt.xlabel('Labels')\nplt.ylabel('Frequency')\nplt.title('Frequency Distribution of Flowers')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-04T18:45:32.153308Z","iopub.execute_input":"2023-10-04T18:45:32.154008Z","iopub.status.idle":"2023-10-04T18:45:32.849265Z","shell.execute_reply.started":"2023-10-04T18:45:32.153976Z","shell.execute_reply":"2023-10-04T18:45:32.848337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Here I split the data into train, validation, and test sets.\ntrainx, testx, trainy, testy = tts(all_imgs, all_labels, test_size = 0.2, random_state = 7)\nvalx, testx, valy, testy = tts(testx, testy, test_size = 0.5, random_state = 7)\n# Create datasets corresponding to train, valid, and test data, to load them later on via dataloaders to the neural network.\nclass data_set(Dataset):\n    def __init__(self, img, label, transform = None):\n        self.img = img\n        self.label = label\n        self.transform = transform\n    def __getitem__(self, idx):\n        img = self.img[idx]\n        label = self.label[idx]\n        if self.transform:\n            img = self.transform(img)\n        return img, label\n    def __len__(self):\n        return len(self.label)\n    \ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Resize((112, 112), interpolation=Image.BILINEAR, antialias = None)\n])\n\nbatch_size = 128 # This batch size seems to work well with my resources!\ntrain_set = data_set(trainx, trainy, transform = transform)\nval_set = data_set(valx, valy, transform = transform)\ntest_set = data_set(testx, testy, transform = transform)\n\ntrain_loader = DataLoader(train_set, batch_size, shuffle = True)\nval_loader = DataLoader(val_set, batch_size, shuffle = False)\ntest_loader = DataLoader(test_set, batch_size, shuffle = False)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T21:39:07.117085Z","iopub.execute_input":"2023-10-04T21:39:07.118128Z","iopub.status.idle":"2023-10-04T21:39:07.133017Z","shell.execute_reply.started":"2023-10-04T21:39:07.118083Z","shell.execute_reply":"2023-10-04T21:39:07.132016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now Let's load the ResNet 50 and intiialize its hyperparamteres.\n\nresnet = models.resnet50(weights=models.ResNet50_Weights.DEFAULT) # set the model to be loaded as pretrained\nfor param in resnet.parameters(): # I freeze the weights to only train the classifier layer (here it is frozen),\n    param.requires_grad = False     # while keeping the model's feature extraction capability\n\n\n# And next I modify the final later to output the same number of categories in the dataset.\nresnet.fc = nn.Sequential(\n            nn.Linear(resnet.fc.in_features, 102),\n            nn.Softmax(dim = 1)  # Add a softmax activation to produce class probabilities.\n            )\n\nresnet.to(DEVICE) # Hopefully Cuda!\nprint('Resnet 50 Loaded!')\n\n# And here I set the loss function to cross entropy loss since I want to multi-class classification\nloss_f = nn.CrossEntropyLoss()\nepochs = 25","metadata":{"execution":{"iopub.status.busy":"2023-10-04T21:40:52.258503Z","iopub.execute_input":"2023-10-04T21:40:52.259193Z","iopub.status.idle":"2023-10-04T21:40:52.712300Z","shell.execute_reply.started":"2023-10-04T21:40:52.259162Z","shell.execute_reply":"2023-10-04T21:40:52.711301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now I can train the pretrained Model on train set.\n# Also I assign some variables to measure the model's performance while training.\ntrain_losses = list()\ntrain_accuracies = list()\nval_losses = list()\nval_accuracies = list()\n\nfor epoch in tqdm(range(epochs)): \n    lr = 2e-3 * 0.99 ** (epoch-1) # use learning rate decay\n    optimizer = optim.Adam(resnet.parameters(), lr = lr) # Use Adam optimizer for faster gradient decent steps\n    resnet.train() # training mode on\n\n    running_loss = 0.0\n    num_samples = 0\n    num_correct = 0\n    for img, label in train_loader:\n        img, label = img.to(DEVICE), label.to(DEVICE) # move all variable to GPU before feeding to network\n        optimizer.zero_grad() # do the training loop and update model parameters (FC layer only)\n        output = resnet(img)\n        loss = loss_f(output, label)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        _, predicted = torch.max(output, 1)  # Get the class with the highest probability\n        _, true_label = torch.max(label, 1)\n        num_samples += label.size(0)\n        num_correct += (predicted == true_label).sum().item()\n        \n    train_accuracy = 100 * num_correct / num_samples\n    epoch_loss = running_loss / len(train_loader)\n    train_losses.append(epoch_loss)\n    train_accuracies.append(train_accuracy)\n    \n    with torch.no_grad():\n        vr_loss = 0\n        val_samples = 0\n        val_corrects = 0\n        for img, label in val_loader:\n            img, label = img.to(DEVICE), label.to(DEVICE)\n            output = resnet(img)\n            _, predicted = torch.max(output, 1)\n            _, true_label = torch.max(label, 1)\n            \n            val_samples += label.size(0)\n            val_corrects += (predicted == true_label).sum().item()\n            vr_loss += loss_f(output, label).item()\n        val_accuracy = 100 * val_corrects/val_samples\n        val_loss = vr_loss/len(val_loader)\n        print(f\"Epoch [{epoch + 1}/{epochs}] - Training Loss: {epoch_loss:.4f} - Training Accuracy: {train_accuracy:.2f}%\")\n        print(f\"Epoch [{epoch + 1}/{epochs}] - Validation Loss: {val_loss:.4f} - Validation Accuracy: {val_accuracy:.2f}%\")\n        val_losses.append(val_loss)\n        val_accuracies.append(val_accuracy)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T21:40:54.117558Z","iopub.execute_input":"2023-10-04T21:40:54.118539Z","iopub.status.idle":"2023-10-04T21:44:48.955982Z","shell.execute_reply.started":"2023-10-04T21:40:54.118497Z","shell.execute_reply":"2023-10-04T21:44:48.954467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now the final step: test the model\nnum_sample = 0\nnum_correct = 0\npreds = []\ntrue_labels = []\nwith torch.no_grad():\n    for img, label in test_loader:\n        img, label = img.to(DEVICE), label.to(DEVICE)\n        output = resnet(img) \n        _, predicted = torch.max(output, 1)\n        _, true_label = torch.max(label, 1)\n        preds += predicted.cpu().numpy().tolist()\n        true_labels += true_label.cpu().numpy().tolist()\n        num_sample += label.size(0)\n        num_correct += (predicted == true_label).sum().item()\n    test_accuracy = 100 * num_correct/num_sample\n    print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n","metadata":{"execution":{"iopub.status.busy":"2023-10-04T21:44:54.022684Z","iopub.execute_input":"2023-10-04T21:44:54.023095Z","iopub.status.idle":"2023-10-04T21:44:56.739410Z","shell.execute_reply.started":"2023-10-04T21:44:54.023065Z","shell.execute_reply":"2023-10-04T21:44:56.738399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# And visualize the performance\n# plot train loss by epoch\nplt.figure(figsize=(12, 4))\nplt.subplot(1, 2, 1)\nplt.plot(train_losses, label='Training Loss', color = 'blue')\nplt.plot(val_losses, label='Validation Loss', color = 'red')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.savefig('Loss_plot.png')\n\n# plot training and test accuracy curves\nplt.subplot(1, 2, 2)\nplt.plot(train_accuracies, label='Training Accuracy', color = 'blue')\nplt.plot(val_accuracies, label='Validation Accuracy', color = 'red')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy (%)')\nplt.axhline(y=test_accuracy, color='red', linestyle='--', label='Test Accuracy')\nplt.legend()\nplt.savefig('Acc_plot.png')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-04T21:44:58.968350Z","iopub.execute_input":"2023-10-04T21:44:58.968722Z","iopub.status.idle":"2023-10-04T21:44:59.603681Z","shell.execute_reply.started":"2023-10-04T21:44:58.968694Z","shell.execute_reply":"2023-10-04T21:44:59.602774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_count = Counter(preds)\ntrue_count = Counter(true_labels)\n# And now let's visualize the distribution of frequencies:\np_values = pred_count.keys()\np_counts = pred_count.values()\nplt.bar(p_values, p_counts, label = 'Predicted Labels')\n\nt_values = list(true_count.keys())\nt_counts = list(true_count.values())\n# Create the bar chart\nplt.bar(t_values, t_counts, alpha=0.25, color='red', label='True Labels')\n\nplt.xlabel('Labels')\nplt.ylabel('Frequency')\nplt.title('Frequency of Predictions vs True Labels')\nplt.legend()\nplt.savefig('pred_vs_true_plot.png')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-04T21:45:09.810184Z","iopub.execute_input":"2023-10-04T21:45:09.810527Z","iopub.status.idle":"2023-10-04T21:45:10.462361Z","shell.execute_reply.started":"2023-10-04T21:45:09.810499Z","shell.execute_reply":"2023-10-04T21:45:10.461471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}